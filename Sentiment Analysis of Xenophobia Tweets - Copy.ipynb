{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "#Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import os\n",
    "os.environ[\"PROJ_LIB\"] = r'C:\\Users\\blmalumi\\AppData\\Local\\Continuum\\anaconda3\\pkgs\\proj4-5.2.0-ha925a31_1\\Library\\share'\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tweets = pd.read_csv('xenophobia.csv', encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing del RT @blablabla:\n",
    "tweets['tweetos'] = '' \n",
    "\n",
    "#add tweetos first part\n",
    "for i in range(len(tweets['text'])):\n",
    "    try:\n",
    "        tweets['tweetos'][i] = tweets['text'].str.split(' ')[i][0]\n",
    "    except AttributeError:    \n",
    "        tweets['tweetos'][i] = 'other'\n",
    "\n",
    "#Preprocessing tweetos. select tweetos contains 'RT @'\n",
    "for i in range(len(tweets['text'])):\n",
    "    if tweets['tweetos'].str.contains('@')[i]  == False:\n",
    "        tweets['tweetos'][i] = 'other'\n",
    "        \n",
    "# remove URLs, RTs, and twitter handles\n",
    "for i in range(len(tweets['text'])):\n",
    "    tweets['text'][i] = \" \".join([word for word in tweets['text'][i].split()\n",
    "                                if 'http' not in word and '@' not in word and '<' not in word])\n",
    "\n",
    "\n",
    "print(tweets['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets['text'] = tweets['text'].apply(lambda x: re.sub('[!@$:).;,?&]', '', x.lower()))\n",
    "# tweets['text'] = tweets['text'].apply(lambda x: re.sub('  ', ' ', x))\n",
    "tweets['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud(tweets,col):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    wordcloud = WordCloud(background_color=\"white\",stopwords=stopwords,random_state = 2016).generate(\" \".join([i for i in tweets[col]]))\n",
    "    plt.figure( figsize=(20,10), facecolor='k')\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Good Morning Datascience+\")\n",
    "wordcloud(tweets,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets['country'] = tweets['country'].apply(lambda x: x.lower())\n",
    "# tweets['country'].replace('states united','united states',inplace=True)\n",
    "# tweets['country'].replace('united states','usa',inplace=True)\n",
    "# tweets['country'].replace('united Kingdom','uk',inplace=True)\n",
    "# tweets['country'].replace('republic philippines','philippines republic',inplace=True)\n",
    "# wordcloud(tweets, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['source'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['source'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_type = tweets.groupby(['source'])['followers_count'].sum()\n",
    "print(tweets_by_type)\n",
    "plt.title('Number of followers by Source', bbox={'facecolor':'0.8', 'pad':0})\n",
    "tweets_by_type.transpose().plot(kind='bar',figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['source_new2'] = ''\n",
    "labels = ['TweetCaster for Android' ,'TwitPane for Android','Twitter for iPhone','Others','Twitter for iPad','LinkedIn','Hootsuite Inc.','Twibble.io']\n",
    "labels = list(labels)\n",
    "for i in range(len(tweets['source'])):\n",
    "    if tweets['source'][i] not in ['Twitter for Android','Instagram','Twitter Web Client','Twitter for iPhone','LinkedIn','Hootsuite Inc.','Twibble.io']:\n",
    "        tweets['source_new2'][i] = 'Others'\n",
    "    else:\n",
    "        tweets['source_new2'][i] = tweets['source'][i] \n",
    "\n",
    "tweets_by_type2 = tweets.groupby(['source_new2'])['followers_count'].sum()\n",
    "\n",
    "tweets_by_type2.rename(\"\",inplace=True)\n",
    "explode = [1, 0, 0, 0, 0, 0,0,0]\n",
    "explode = list(explode)\n",
    "print(tweets_by_type2.transpose())\n",
    "tweets_by_type2.transpose().plot(kind='pie',figsize=(20, 15),autopct='%1.1f%%',shadow=True,explode=explode, labels=labels)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=6, borderaxespad=0.)\n",
    "plt.title('Number of followers by Source bis', bbox={'facecolor':'0.8', 'pad':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(20,10), facecolor='k')\n",
    "m = Basemap(projection='mill',resolution=None,llcrnrlat=-90,urcrnrlat=90,llcrnrlon=-180,urcrnrlon=180)\n",
    "m.etopo()\n",
    "xpt,ypt = m(np.array(tweets['place_lon']),np.array(tweets['place_lat']))\n",
    "lon,lat = m(xpt,ypt,inverse=True)\n",
    "m.plot(xpt,ypt,'ro',markersize=np.sqrt(5)) \n",
    "plt.title('Repartition on the globe', bbox={'facecolor':'0.8', 'pad':3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in tweets['text']]       \n",
    "vectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\n",
    "X = vectorizer.fit_transform(tweets['text_lem'].str.upper())\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "tweets['sentiment_compound_polarity']=tweets.text_lem.apply(lambda x:sid.polarity_scores(x)['compound'])\n",
    "tweets['sentiment_neutral']=tweets.text_lem.apply(lambda x:sid.polarity_scores(x)['neu'])\n",
    "tweets['sentiment_negative']=tweets.text_lem.apply(lambda x:sid.polarity_scores(x)['neg'])\n",
    "tweets['sentiment_pos']=tweets.text_lem.apply(lambda x:sid.polarity_scores(x)['pos'])\n",
    "tweets['sentiment_type']=''\n",
    "tweets.loc[tweets.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
    "tweets.loc[tweets.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
    "tweets.loc[tweets.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sentiment = tweets.groupby(['sentiment_type'])['sentiment_neutral'].count()\n",
    "tweets_sentiment.rename(\"\",inplace=True)\n",
    "explode = (1, 0, 0)\n",
    "plt.subplot(221)\n",
    "tweets_sentiment.transpose().plot(kind='barh',figsize=(20, 20))\n",
    "plt.title('Sentiment Analysis 1', bbox={'facecolor':'0.8', 'pad':0})\n",
    "plt.subplot(222)\n",
    "tweets_sentiment.plot(kind='pie',figsize=(20, 20),autopct='%1.1f%%',shadow=True,explode=explode)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=3, borderaxespad=0.)\n",
    "plt.title('Sentiment Analysis 2', bbox={'facecolor':'0.8', 'pad':0})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets.sentiment_type == 'NEGATIVE'].text.reset_index(drop = True)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets= tweets.groupby(['created_at'])['retweet_count'].sum()\n",
    "new_tweets\n",
    "new_tweets.transpose().plot(kind='bar',figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi['tidy_tweet'] = combi['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "tweets[\"created_at\"] = pd.to_datetime(tweets[\"created_at\"])\n",
    "tweets[\"user_created\"] = pd.to_datetime(tweets[\"user_created\"])\n",
    "\n",
    "tweets[\"user_age\"] = tweets[\"user_created\"].apply(lambda x: (datetime.now() - x).total_seconds() / 3600 / 24 / 365)\n",
    "\n",
    "\n",
    "plt.hist(tweets[\"user_age\"])\n",
    "plt.title(\"Tweets mentioning xenophobia\")\n",
    "plt.xlabel(\"Twitter account age in years\")\n",
    "plt.ylabel(\"# of tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing value for contries\n",
    "\n",
    "tweets['location'].fillna(tweets['location'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tweets= tweets.groupby(['location'])['retweet_count'].sum()\n",
    "new_tweets\n",
    "new_tweets.transpose().plot(kind='bar',figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frq = tweets['location'].value_counts()/tweets.shape[0]\n",
    "combine = frq.loc[frq.values < 0.0005].index\n",
    "print(combine)\n",
    "# for cat in combine:\n",
    "#     tweets['location'].replace({cat:'Others'},inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = list(tweets.dtypes.loc[tweets.dtypes=='object'].index)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tweets['location'].value_counts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['country1'] = tweets['location']\n",
    "tweets['country1'].replace('Johannesburg, South Africa','South Africa',inplace=True)\n",
    "tweets['country1'].replace('Cape Town South Africa','South Africa',inplace=True)\n",
    "tweets['country1'].replace('Cape Town','South Africa',inplace=True)\n",
    "\n",
    "tweets['country1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frq = tweets['country1'].value_counts()/tweets.shape[0]\n",
    "combine = frq.loc[frq.values < 0.0004].index\n",
    "\n",
    "for cat in combine:\n",
    "    tweets['country1'].replace({cat:'Others'},inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['country1'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets= tweets.groupby(['country1'])['retweet_count'].sum()\n",
    "new_tweets\n",
    "new_tweets.transpose().plot(kind='bar',figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['country1'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
