{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import os\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "# Add your Twitter API credentials\n",
    "consumer_key = \"xm94pAUphNozJUwY4SzFM8nnT\"\n",
    "consumer_secret = \"k7gFj8K4kE344d8kyBA67xabwL5XMiZXGmDmTjnx1PDWuI0bRO\"\n",
    "access_key = \"4512685235-ckOFfc3r6QiASVdJBYNUih1CPZWHpVOquSDSon3\"\n",
    "access_secret = \"AAEJmUPJtQTYz36qfjjmmZx0fyqH6cHaXjuyM0KwBDMHf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling authentication with Twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "\n",
    "# Create a wrapper for the API provided by Twitter\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"southafrica+xenophobia -filter:retweets\"\n",
    "date_since = \"2017-05-18\"\n",
    "\n",
    "# Define until what date we are looking for tweets\n",
    "date_until = \"\"\n",
    "\n",
    "# Total tweets to gather in our search\n",
    "totalTweets = 1000\n",
    "\n",
    "# Numbers of tweets to return per page, max is 100. Default is 15.\n",
    "count = 100\n",
    "\n",
    "# Filter by language\n",
    "lang = \"en\"\n",
    "\n",
    "'''Filter by latitude,longitude,radius.\n",
    "# 37.781157 -122.398720 1mi'''\n",
    "geocode = \"\"\n",
    "\n",
    "# Filter by recent, popular or mixed.\n",
    "result_type = \"mixed\"\n",
    "\n",
    "'''Include info on entities found in Tweets, including hashtags,\n",
    "links, and mentions. Set to True or False'''\n",
    "include_entities = True\n",
    "\n",
    "# Set the name for CSV file  where the tweets will be saved\n",
    "filename = \"xenophobia_tweets\"\n",
    "new_search = search_words + \" -filter:retweets\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for handling pagination in our search\n",
    "def limit_handled(cursor):\n",
    "    while True:\n",
    "        try:\n",
    "            yield cursor.next()\n",
    "        except tweepy.RateLimitError:\n",
    "            print('Reached rate limited Sleeping for >15 minutes')\n",
    "            time.sleep(15 * 61)\n",
    "        except StopIteration:\n",
    "            return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(new_search, date_since):\n",
    "    tweets = tweepy.Cursor(api.search, \n",
    "                          q=search_words,\n",
    "                           lang=\"en\",\n",
    "                           result_type=result_type,\n",
    "                           since=date_since).items(totalTweets)\n",
    "   \n",
    "\n",
    "        \n",
    "    twitter_object = [[ tweet.user.created_at,\n",
    "               tweet.text, tweet.retweet_count, tweet.favorited, tweet.truncated, tweet.id_str, tweet.in_reply_to_screen_name,\n",
    "               tweet.source, tweet.retweeted, tweet.created_at, tweet.in_reply_to_status_id_str, tweet.in_reply_to_user_id, \n",
    "               tweet.lang, tweet.user.listed_count, tweet.user.verified, tweet.user.location, tweet.user.statuses_count,\n",
    "               tweet.user.followers_count, tweet.user.favourites_count, tweet.user.protected, tweet.user.time_zone,\n",
    "               tweet.user.url] for tweet in tweets]\n",
    "    try:\n",
    "\n",
    "        tweet_text = pd.DataFrame(data=twitter_object, columns=[\"user_created\",\"text\",\"retweet_count\",\"favorited\",\"truncated\",\"id_str\",\n",
    "                                                        \"in_reply_to_screen_name\",\"source\",\"retweeted\",\"created_at\",\"in_reply_to_status_id_str\",\"in_reply_to_user_id\",\n",
    "                                                       \"lang\",\"listed_count\",\"verified\",\"location\",\"statuses_count\",\"followers_count\",\"favourites_count\",\"protected\",\"time_zone\",\"user_url\"])\n",
    "\n",
    "        #writes data frame to a csv file\n",
    "       \n",
    "        tweet_text.to_csv('tweets_samples2.csv')\n",
    "\n",
    "    except Exception as e:\n",
    "            print('Encountered Exception:', e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_text.to_csv('tweets_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work():\n",
    "    \n",
    "        # Initializing the Twitter search\n",
    "        data = search_tweets(search_words, date_since)\n",
    "        try:\n",
    "            data = search_tweets(search_words, date_since)\n",
    "\n",
    "        # Stop temporarily when hitting Twitter rate Limit\n",
    "        except tweepy.RateLimitError:\n",
    "            print(\"RateLimitError...waiting ~15 minutes to continue\")\n",
    "            time.sleep(20)\n",
    "            search_tweets(search_words, date_since)\n",
    "        except (RuntimeError) as exc:\n",
    "            print(\"Runtime error...waiting ~15 minutes to continue\")\n",
    "            time.sleep(1001)\n",
    "            search_tweets(search_words, date_since)\n",
    "\n",
    "        # Stop temporarily when getting a timeout or connection error\n",
    "#         except (Timeout, ssl.SSLError, ReadTimeoutError,ConnectionError) as exc:\n",
    "#             print(\"Timeout/connection error...waiting ~15 minutes to continue\")\n",
    "#             time.sleep(1001)\n",
    "#             search_tweets(search_words, date_since)\n",
    "\n",
    "        # Stop temporarily when getting other errors\n",
    "        except tweepy.TweepError as e:\n",
    "            if 'Failed to send request:' in e.reason:\n",
    "                print(\"Time out error caught.\")\n",
    "                time.sleep(1001)\n",
    "                search_tweets(search_words, date_since)\n",
    "            elif'Too Many Requests' in e.reason:\n",
    "                print(\"Too many requests, sleeping for 15 min\")\n",
    "                time.sleep(1001)\n",
    "                search_tweets(search_words, date_since)\n",
    "            else:\n",
    "                print(e)\n",
    "                print(\"Other error with this user...passing\")\n",
    "                pass\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
